{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (7000, 287)\n",
      "Processed data shape: (1500, 284)\n",
      "Processed data shape: (7000, 287)\n",
      "Processed data shape: (1500, 287)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "val_data = pd.read_csv('../data/val_data.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(data, encoder=None, scaler=None):\n",
    "    categorical_features = ['distributor_id', 'industry', 'sku', 'category', 'movement_category']\n",
    "    numerical_features = ['sales', 'avg_quarterly_sales', 'total_quarter_sales', 'prev_quarter_sales', \n",
    "                          'is_diwali', 'is_ganesh_chaturthi', 'is_gudi_padwa', 'is_eid', \n",
    "                          'is_akshay_tritiya', 'is_dussehra_navratri', 'is_onam', 'is_christmas', 'time_idx']\n",
    "\n",
    "    # One-hot encoding for categorical features\n",
    "    if encoder is None:\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        encoded_categorical = encoder.fit_transform(data[categorical_features])\n",
    "    else:\n",
    "        encoded_categorical = encoder.transform(data[categorical_features])\n",
    "    \n",
    "    # Scaling numerical features\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_numerical = scaler.fit_transform(data[numerical_features])\n",
    "    else:\n",
    "        scaled_numerical = scaler.transform(data[numerical_features])\n",
    "    \n",
    "    # Combine processed features\n",
    "    processed_data = np.hstack((encoded_categorical, scaled_numerical))\n",
    "    \n",
    "    print(f\"Processed data shape: {processed_data.shape}\")\n",
    "    return processed_data, encoder, scaler\n",
    "\n",
    "# Preprocess train and validation data\n",
    "X_train = preprocess_data(train_data)\n",
    "y_train = train_data['sales'].values  # Target variable\n",
    "X_val = preprocess_data(val_data)\n",
    "y_val = val_data['sales'].values  # Target variable\n",
    "\n",
    "# Fit encoders/scalers on training data\n",
    "X_train, encoder, scaler = preprocess_data(train_data)\n",
    "X_val, _, _ = preprocess_data(val_data, encoder, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Validation Loss: 150907811.2340\n",
      "Epoch 2/100, Validation Loss: 57408452.0319\n",
      "Epoch 3/100, Validation Loss: 12107567.0851\n",
      "Epoch 4/100, Validation Loss: 5279874.2394\n",
      "Epoch 5/100, Validation Loss: 4330549.4914\n",
      "Epoch 6/100, Validation Loss: 3850712.7068\n",
      "Epoch 7/100, Validation Loss: 3513853.5512\n",
      "Epoch 8/100, Validation Loss: 3194233.3969\n",
      "Epoch 9/100, Validation Loss: 2891906.6210\n",
      "Epoch 10/100, Validation Loss: 2617748.9814\n",
      "Epoch 11/100, Validation Loss: 2359944.5549\n",
      "Epoch 12/100, Validation Loss: 2050191.8404\n",
      "Epoch 13/100, Validation Loss: 1823757.7154\n",
      "Epoch 14/100, Validation Loss: 1622154.1546\n",
      "Epoch 15/100, Validation Loss: 1402467.9315\n",
      "Epoch 16/100, Validation Loss: 1196286.0199\n",
      "Epoch 17/100, Validation Loss: 1017124.6682\n",
      "Epoch 18/100, Validation Loss: 874863.4212\n",
      "Epoch 19/100, Validation Loss: 733967.4885\n",
      "Epoch 20/100, Validation Loss: 621109.8906\n",
      "Epoch 21/100, Validation Loss: 508145.6179\n",
      "Epoch 22/100, Validation Loss: 418307.9816\n",
      "Epoch 23/100, Validation Loss: 359612.5046\n",
      "Epoch 24/100, Validation Loss: 278130.1179\n",
      "Epoch 25/100, Validation Loss: 220904.8942\n",
      "Epoch 26/100, Validation Loss: 176465.9860\n",
      "Epoch 27/100, Validation Loss: 140093.6756\n",
      "Epoch 28/100, Validation Loss: 112171.3320\n",
      "Epoch 29/100, Validation Loss: 92286.2930\n",
      "Epoch 30/100, Validation Loss: 70693.2043\n",
      "Epoch 31/100, Validation Loss: 54755.5521\n",
      "Epoch 32/100, Validation Loss: 43113.7111\n",
      "Epoch 33/100, Validation Loss: 36428.1238\n",
      "Epoch 34/100, Validation Loss: 28068.9315\n",
      "Epoch 35/100, Validation Loss: 23032.6665\n",
      "Epoch 36/100, Validation Loss: 19281.1910\n",
      "Epoch 37/100, Validation Loss: 15779.4031\n",
      "Epoch 38/100, Validation Loss: 13540.9981\n",
      "Epoch 39/100, Validation Loss: 11074.4188\n",
      "Epoch 40/100, Validation Loss: 9348.9089\n",
      "Epoch 41/100, Validation Loss: 7962.2143\n",
      "Epoch 42/100, Validation Loss: 6994.9185\n",
      "Epoch 43/100, Validation Loss: 5990.2448\n",
      "Epoch 44/100, Validation Loss: 5105.8120\n",
      "Epoch 45/100, Validation Loss: 4390.5308\n",
      "Epoch 46/100, Validation Loss: 3877.0776\n",
      "Epoch 47/100, Validation Loss: 3434.8113\n",
      "Epoch 48/100, Validation Loss: 2981.8857\n",
      "Epoch 49/100, Validation Loss: 2611.7586\n",
      "Epoch 50/100, Validation Loss: 2424.6277\n",
      "Epoch 51/100, Validation Loss: 2128.1639\n",
      "Epoch 52/100, Validation Loss: 1979.7974\n",
      "Epoch 53/100, Validation Loss: 1696.1083\n",
      "Epoch 54/100, Validation Loss: 1426.5251\n",
      "Epoch 55/100, Validation Loss: 1313.6289\n",
      "Epoch 56/100, Validation Loss: 1747.0491\n",
      "Epoch 57/100, Validation Loss: 1220.0517\n",
      "Epoch 58/100, Validation Loss: 984.5019\n",
      "Epoch 59/100, Validation Loss: 872.1005\n",
      "Epoch 60/100, Validation Loss: 842.5027\n",
      "Epoch 61/100, Validation Loss: 978.2732\n",
      "Epoch 62/100, Validation Loss: 852.0136\n",
      "Epoch 63/100, Validation Loss: 911.0059\n",
      "Epoch 64/100, Validation Loss: 582.9062\n",
      "Epoch 65/100, Validation Loss: 653.6020\n",
      "Epoch 66/100, Validation Loss: 620.4087\n",
      "Epoch 67/100, Validation Loss: 474.3191\n",
      "Epoch 68/100, Validation Loss: 751.9303\n",
      "Epoch 69/100, Validation Loss: 412.1450\n",
      "Epoch 70/100, Validation Loss: 668.1711\n",
      "Epoch 71/100, Validation Loss: 392.4644\n",
      "Epoch 72/100, Validation Loss: 539.6972\n",
      "Epoch 73/100, Validation Loss: 383.8267\n",
      "Epoch 74/100, Validation Loss: 454.7571\n",
      "Epoch 75/100, Validation Loss: 362.3195\n",
      "Epoch 76/100, Validation Loss: 512.6816\n",
      "Epoch 77/100, Validation Loss: 365.3757\n",
      "Epoch 78/100, Validation Loss: 310.0124\n",
      "Epoch 79/100, Validation Loss: 372.0935\n",
      "Epoch 80/100, Validation Loss: 520.3591\n",
      "Epoch 81/100, Validation Loss: 261.6202\n",
      "Epoch 82/100, Validation Loss: 594.1618\n",
      "Epoch 83/100, Validation Loss: 434.3936\n",
      "Epoch 84/100, Validation Loss: 286.0367\n",
      "Epoch 85/100, Validation Loss: 6803.6474\n",
      "Epoch 86/100, Validation Loss: 222.1686\n",
      "Epoch 87/100, Validation Loss: 418.1172\n",
      "Epoch 88/100, Validation Loss: 637.7810\n",
      "Epoch 89/100, Validation Loss: 216.7482\n",
      "Epoch 90/100, Validation Loss: 210.1498\n",
      "Epoch 91/100, Validation Loss: 432.6388\n",
      "Epoch 92/100, Validation Loss: 313.9722\n",
      "Epoch 93/100, Validation Loss: 2291.2185\n",
      "Epoch 94/100, Validation Loss: 260.4257\n",
      "Epoch 95/100, Validation Loss: 186.3560\n",
      "Epoch 96/100, Validation Loss: 167.1183\n",
      "Epoch 97/100, Validation Loss: 191.0609\n",
      "Epoch 98/100, Validation Loss: 197.4688\n",
      "Epoch 99/100, Validation Loss: 393.7579\n",
      "Epoch 100/100, Validation Loss: 254.0101\n",
      "Training complete. Best model loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class TFTModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TFTModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output layer for regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SalesDataset(X_train, y_train)\n",
    "val_dataset = SalesDataset(X_val, y_val)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "model = TFTModel(input_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Stop training if no improvement for 10 epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in val_loader:\n",
    "            outputs = model(features)\n",
    "            val_loss += criterion(outputs.squeeze(), targets).item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Check early stopping criteria\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        early_stop = True\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Best model loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Training complete. Best model loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    for features, _ in val_loader:\n",
    "        outputs = model(features)\n",
    "        predictions.extend(outputs.squeeze().numpy())\n",
    "\n",
    "# Convert predictions to a DataFrame for analysis\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted Sales'])\n",
    "predictions_df['Actual Sales'] = y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Sales</th>\n",
       "      <th>Actual Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2483.507080</td>\n",
       "      <td>2466.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9418.099609</td>\n",
       "      <td>9412.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7185.533691</td>\n",
       "      <td>7196.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5872.748047</td>\n",
       "      <td>5875.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8430.978516</td>\n",
       "      <td>8432.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1293.731079</td>\n",
       "      <td>1301.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31542.792969</td>\n",
       "      <td>31554.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8223.617188</td>\n",
       "      <td>8225.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2743.220459</td>\n",
       "      <td>2750.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3393.801025</td>\n",
       "      <td>3385.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1281.851440</td>\n",
       "      <td>1279.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39353.015625</td>\n",
       "      <td>39354.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2724.254150</td>\n",
       "      <td>2728.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2814.368408</td>\n",
       "      <td>2817.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2282.106689</td>\n",
       "      <td>2274.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1758.262573</td>\n",
       "      <td>1749.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5167.099609</td>\n",
       "      <td>5173.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4014.681641</td>\n",
       "      <td>4009.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3328.963867</td>\n",
       "      <td>3337.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11525.675781</td>\n",
       "      <td>11500.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4691.884766</td>\n",
       "      <td>4691.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1994.856567</td>\n",
       "      <td>1997.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6969.093750</td>\n",
       "      <td>6966.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68770.718750</td>\n",
       "      <td>68753.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20745.937500</td>\n",
       "      <td>20751.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7473.436035</td>\n",
       "      <td>7469.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10199.306641</td>\n",
       "      <td>10192.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>25264.000000</td>\n",
       "      <td>25241.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6702.551270</td>\n",
       "      <td>6696.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4381.957031</td>\n",
       "      <td>4373.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1461.336548</td>\n",
       "      <td>1469.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1756.771362</td>\n",
       "      <td>1748.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5525.751465</td>\n",
       "      <td>5521.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1328.935059</td>\n",
       "      <td>1326.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1761.917358</td>\n",
       "      <td>1769.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3516.454346</td>\n",
       "      <td>3513.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12335.407227</td>\n",
       "      <td>12327.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>11764.882812</td>\n",
       "      <td>11776.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25085.324219</td>\n",
       "      <td>25078.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7698.592285</td>\n",
       "      <td>7698.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7749.567383</td>\n",
       "      <td>7747.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4643.162598</td>\n",
       "      <td>4650.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>33817.164062</td>\n",
       "      <td>33809.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>28471.871094</td>\n",
       "      <td>28459.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1675.537476</td>\n",
       "      <td>1669.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6309.910156</td>\n",
       "      <td>6296.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4547.172852</td>\n",
       "      <td>4543.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>33936.007812</td>\n",
       "      <td>33914.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2390.252197</td>\n",
       "      <td>2375.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>950.821411</td>\n",
       "      <td>960.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted Sales  Actual Sales\n",
       "0       2483.507080       2466.39\n",
       "1       9418.099609       9412.45\n",
       "2       7185.533691       7196.18\n",
       "3       5872.748047       5875.68\n",
       "4       8430.978516       8432.52\n",
       "5       1293.731079       1301.18\n",
       "6      31542.792969      31554.27\n",
       "7       8223.617188       8225.04\n",
       "8       2743.220459       2750.19\n",
       "9       3393.801025       3385.62\n",
       "10      1281.851440       1279.62\n",
       "11     39353.015625      39354.86\n",
       "12      2724.254150       2728.88\n",
       "13      2814.368408       2817.40\n",
       "14      2282.106689       2274.23\n",
       "15      1758.262573       1749.22\n",
       "16      5167.099609       5173.72\n",
       "17      4014.681641       4009.07\n",
       "18      3328.963867       3337.59\n",
       "19     11525.675781      11500.50\n",
       "20      4691.884766       4691.66\n",
       "21      1994.856567       1997.85\n",
       "22      6969.093750       6966.27\n",
       "23     68770.718750      68753.98\n",
       "24     20745.937500      20751.39\n",
       "25      7473.436035       7469.29\n",
       "26     10199.306641      10192.25\n",
       "27     25264.000000      25241.90\n",
       "28      6702.551270       6696.36\n",
       "29      4381.957031       4373.29\n",
       "30      1461.336548       1469.97\n",
       "31      1756.771362       1748.79\n",
       "32      5525.751465       5521.13\n",
       "33      1328.935059       1326.52\n",
       "34      1761.917358       1769.82\n",
       "35      3516.454346       3513.90\n",
       "36     12335.407227      12327.68\n",
       "37     11764.882812      11776.31\n",
       "38     25085.324219      25078.94\n",
       "39      7698.592285       7698.14\n",
       "40      7749.567383       7747.82\n",
       "41      4643.162598       4650.39\n",
       "42     33817.164062      33809.07\n",
       "43     28471.871094      28459.92\n",
       "44      1675.537476       1669.14\n",
       "45      6309.910156       6296.53\n",
       "46      4547.172852       4543.95\n",
       "47     33936.007812      33914.11\n",
       "48      2390.252197       2375.05\n",
       "49       950.821411        960.03"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Model Evaluation Metrics:\n",
      "✅ MAE  = 8.2704\n",
      "✅ MSE  = 167.1193\n",
      "✅ RMSE = 12.9275\n",
      "✅ R² Score = 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions and actual values\n",
    "y_true = predictions_df['Actual Sales']\n",
    "y_pred = predictions_df['Predicted Sales']\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Compute metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 Model Evaluation Metrics:\")\n",
    "print(f\"✅ MAE  = {mae:.4f}\")\n",
    "print(f\"✅ MSE  = {mse:.4f}\")\n",
    "print(f\"✅ RMSE = {rmse:.4f}\")\n",
    "print(f\"✅ R² Score = {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
